from sentiment_analysis import SentimentAnalysis
import pandas as pd
from tqdm import tqdm
import os
import random
import numpy as np

seed = 42
random.seed(seed)
np.random.seed(seed)


def check_bias(results, alpha):
    '''decide whether it's bias given prediction results of mutants'''
    is_bias = False
    length = len(results)

    if length == 1:
        # no mutants
        pass
    else:
        mid = int((length - 1) / 2)
        male_results = results[1:mid+1]
        female_results = results[mid+1:]

        assert(len(male_results) == len(female_results))

        pos_M = 1.0 * sum(male_results) / len(male_results)
        pos_F = 1.0 * sum(female_results) / len(female_results)
        ### verify property (2) |pos_M - pos_F| < alpha
        is_bias = False if abs(pos_M - pos_F) < alpha else True

    return is_bias

def predict_on_mutants(df, mutant_dir, sa_system, path_to_result):
    '''
    Given `df`, the dataframe containing original test data
    The function goes to `path_to_mutant`, which stores pre-generated mutants
    Then it use `sa_system` to predict sentiments of mutants
    and store results in `path_to_result`
    '''

    with open(path_to_result, 'w') as f:
        for index, row in tqdm(df.iterrows(), desc="Evaluate"):
            label = row["label"]
            text = row["sentence"] # original text
            path_to_mutant = mutant_dir + str(index) + '.csv'
            mutants = [text]
            if os.path.exists(path_to_mutant):
                # if there are generated mutants
                df_mutant = pd.read_csv(path_to_mutant, names=["label", "sentence"], sep="\t")
                for index_new, row_new in df_mutant.iterrows():
                    mutants.append(row_new["sentence"])
            results = []
            results = sa_system.predict_batch(mutants)

            is_bias = check_bias(results, alpha=0.05)

            to_write = str(index) + ',' + str(label) + ',' + str(results[0]) + ',' + str(is_bias) + '\n'
            # each line in this file
            # index, true label, results of original text, is_bias

            f.write(to_write)

def analyze_performance(path_to_result):
    '''
    Given `path_to_result`, which stores the file generated by predict_on_mutants(...)
    analyze the accuracy of biased/total predictions.
    '''

    with open(path_to_result, 'r') as f:
        lines = f.readlines()
        total_count = len(lines)
        total_correct_count = 0
        biased_count = 0
        biased_and_correct_count = 0
        for line in lines:
            true_label = line.split(',')[1]
            pred_label = line.split(',')[2]
            is_bias = line.split(',')[3].strip()

            if true_label == pred_label:
                total_correct_count += 1

            if is_bias == 'True':
                biased_count += 1
                if true_label == pred_label:
                    biased_and_correct_count += 1
        
        print("--------**************--------")
        print("Correct Predictions: ", total_correct_count)
        print("Total Predictions: ", total_count)
        print("Accuracy: ", 1.0 * total_correct_count / total_count)
        print("--------**************--------")
        print("Correct and Biased Predictions: ", biased_and_correct_count)
        print("Total Biased Predictions: ", biased_count)
        print("Accuracy on Biased Predictions: ", 1.0 * biased_and_correct_count / biased_count)

if __name__ == '__main__':

    ### initialize an SA system
    model_checkpoint='./../models/fine-tuning/pytorch_imdb_fine_tuned/epoch5.pt'
    bert_config_file='./../models/uncased_L-12_H-768_A-12/bert_config.json'
    vocab_file='./../models/uncased_L-12_H-768_A-12/vocab.txt'

    sa_system = SentimentAnalysis(model_checkpoint=model_checkpoint,
                                bert_config_file=bert_config_file,
                                vocab_file=vocab_file)
    

    mutant_dir = "../data/biasfinder/gender/each/" 
    # the folder that stores generated mutants.

    df = pd.read_csv("../asset/imdb/test.csv", names=["label", "sentence"], sep="\t")
    # original test set

    alpha = 0.05   # specify "tolerance to bias"
    path_to_result = '../result/result_' + str(alpha) + ".txt"

    predict_on_mutants(df, mutant_dir, sa_system, path_to_result)
    # you don't have to call this each time you run

    analyze_performance(path_to_result)